# -*- coding: utf-8 -*-
"""resnet50_tunned.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o8DxSll1oLkpOF4yqGto2qCh9ZfNkAXn
"""

from google.colab import drive
drive.mount('/content/drive')

# Importing dataset
import os
import numpy as np

# Modifying dataset
from torchvision.transforms import transforms
import splitfolders

# Modelling
from torchvision import datasets
import torchvision
import torch
import torchvision.models as models
import torch.nn as nn

#Visualization
from PIL import Image
import matplotlib.pyplot as plt

# Splitting the folders into train and test 

def splitting(original_folder, splitted_folder, ratio):
  path1 = os.path.join(original_folder)
  path2 = os.path.join(splitted_folder)
  return splitfolders.ratio(path1, path2, seed = 0000, ratio = ratio, group_prefix=None)

# Loading the dataset to work with Pytorch library

def dataset(training_set, validation_set, batch_size, num_workers, transform):
  path = os.path.join(training_set)
  path = os.path.join(validation_set)

  train_data = datasets.ImageFolder(training_set, transform=transform)
  valid_data = datasets.ImageFolder(validation_set, transform=transform)

  training_images = torch.utils.data.DataLoader(train_data, batch_size = batch_size, num_workers=num_workers, shuffle=True)
  validation_images = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)
  loader = ({"train" : training_images,
             "valid" : validation_images})
  return loader

# Setting the parameters of the resnet model

def set_parameter_requires_grad(model, extracting_features):
    if extracting_features:
        for param in model.parameters():
            param.requires_grad = False

# Loading the resnet model and  modifying it by adding more layers

def initialize_model(num_classes, feature_extract, use_pretrained=True):
    model = torchvision.models.resnet50(pretrained=use_pretrained)
    set_parameter_requires_grad(model, feature_extract)
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Sequential(torch.nn.Linear(num_ftrs, 128),
                                      torch.nn.ReLU(),
                                       torch.nn.Linear(128, num_classes),
                                       torch.nn.Softmax()
                                      )
    
    return model

# Loading the resnet model and modying it by adding some more layers

def initialize_model_2(num_classes, feature_extract, use_pretrained=True):
    model = torchvision.models.resnet50(pretrained=use_pretrained)
    set_parameter_requires_grad(model, feature_extract)
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Sequential(torch.nn.Linear(num_ftrs, 128),
                                      torch.nn.ReLU(),
                                      torch.nn.Dropout(0.7),
                                       torch.nn.Linear(128, num_classes),
                                      torch.nn.Flatten(),
                                       torch.nn.Sigmoid()

                                      )
    return model

# Function for fitting the model in the dataset

def train(n_epochs, loader, model, optimizer, criterion, use_cuda, save_path):

  train_accuracy_list = []
  train_loss_list = []
  valid_accuracy_list = []
  valid_loss_list = []


  """Implementing a function to obtain training accuracy, training loss,
   validation accuracy and validation loss."""

    # initialize tracker for minimum validation loss
  valid_loss_min = np.Inf
       
  for epoch in range(1, (n_epochs+1)):

        # initialize variables to monitor training loss, training accuracy, validation accuracy and validation loss
        train_loss = 0.0
        valid_loss = 0.0
        train_acc = 0.0
        valid_acc = 0.0
        
        ###################
        # train the model #
        ###################

        model.train()
        
        for batch_idx, (data, target) in enumerate(loader['train']):
            
            # move to GPU
            if use_cuda:
                data, target = data.cuda(), target.cuda()
            
            # clear out the gradients of all Variables from the last step
            optimizer.zero_grad()

            ## find the loss and update the model parameters accordingly
            output = model(data)
            _, preds = torch.max(output, 1)
            loss = criterion(output, target)

            # Derivative of the loss with respect to the parameter
            loss.backward()

           # optimizer to take a step based on the gradients of the parameters
            optimizer.step()
            
            train_acc = train_acc + torch.sum(preds == target.data)

            ## record the average training loss, using something like
            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))
            
            ######################    
            # validate the model #
            ######################
            model.eval()

        for batch_idx, (data, target) in enumerate(loader['valid']):

            # move to GPU
            if use_cuda:
                data, target = data.cuda(), target.cuda()

            ## update the average validation loss and validation accuracy
            output = model(data)
            _, preds = torch.max(output, 1)
            loss = criterion(output, target)
            
            valid_acc = valid_acc + torch.sum(preds == target.data)
            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))

        # Obtaining the training loss, validation loss, training accuracy and validation accuracy   
        train_loss = train_loss/len(loader['train'].dataset)
        valid_loss = valid_loss/len(loader['valid'].dataset)
        train_acc = train_acc/len(loader['train'].dataset)
        valid_acc = valid_acc/len(loader['valid'].dataset)
        
        #Appending the values in the list 
        train_accuracy_list.append(train_acc)
        train_loss_list.append(train_loss)
        valid_accuracy_list.append(valid_acc)
        valid_loss_list.append(valid_loss)
        
        # print training/validation statistics
        print('Epoch: {} \tTraining Acc: {:6f} \tTraining Loss: {:6f} \tValidation Acc: {:6f} \tValidation Loss: {:.6f}'.format(
            epoch,
            train_acc,
            train_loss,
            valid_acc,
            valid_loss
            ))
        
        ## save the model if validation loss has decreased
        if valid_loss <= valid_loss_min:
            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
            valid_loss_min,
            valid_loss))
            torch.save(model.state_dict(), save_path)
            valid_loss_min = valid_loss  
            
  return model