{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U6ujGL9Apz3B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6lpasxilp_85"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.normal_(0.0, 1e-3)\n",
    "        m.bias.data.fill_(0.)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V9FTWRiqABl",
    "outputId": "c5e3f824-b383-4b96-e5da-8a5520a5c8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------\n",
    "# Device configuration\n",
    "#--------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s'%device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AuqIWI4nqAHL"
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Hyper-parameters\n",
    "#--------------------------------\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 200\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg=0.001\n",
    "num_training= 49000\n",
    "num_validation =1000\n",
    "train = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gx405JHf1yPm",
    "outputId": "c16a4e71-2386-48b5-9c51-c104ca6fe5ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasets.zip\n",
      "   creating: datasets/cifar-10-batches-py/\n",
      "  inflating: datasets/cifar-10-batches-py/batches.meta  \n",
      "  inflating: datasets/cifar-10-batches-py/data_batch_1  \n",
      "  inflating: datasets/cifar-10-batches-py/data_batch_2  \n",
      "  inflating: datasets/cifar-10-batches-py/data_batch_3  \n",
      "  inflating: datasets/cifar-10-batches-py/data_batch_4  \n",
      "  inflating: datasets/cifar-10-batches-py/data_batch_5  \n",
      " extracting: datasets/cifar-10-batches-py/readme.html  \n",
      "  inflating: datasets/cifar-10-batches-py/test_batch  \n"
     ]
    }
   ],
   "source": [
    "!unzip datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xqj7FMS_qAMn",
    "outputId": "6292f502-d119-4464-8f88-0ebfcfacc041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "# Load the CIFAR-10 dataset\n",
    "#-------------------------------------------------\n",
    "norm_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                     ])\n",
    "cifar_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
    "                                           train=True,\n",
    "                                           transform=norm_transform,\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
    "                                          train=False,\n",
    "                                          transform=norm_transform\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rGOxPUvjqAS1"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Prepare the training and validation splits\n",
    "#-------------------------------------------------\n",
    "mask = list(range(num_training))\n",
    "train_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
    "mask = list(range(num_training, num_training + num_validation))\n",
    "val_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "S9AbL5UXqAYT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------------------------------\n",
    "# Data loader\n",
    "#-------------------------------------------------\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGrK5X2rqAd2"
   },
   "outputs": [],
   "source": [
    "#======================================================================================\n",
    "# Q4: Implementing multi-layer perceptron in PyTorch\n",
    "#======================================================================================\n",
    "# So far we have implemented a two-layer network using numpy by explicitly\n",
    "# writing down the forward computation and deriving and implementing the\n",
    "# equations for backward computation. This process can be tedious to extend to\n",
    "# large network architectures\n",
    "#\n",
    "# Popular deep-learning libraries like PyTorch and Tensorflow allow us to\n",
    "# quickly implement complicated neural network architectures. They provide\n",
    "# pre-defined layers which can be used as building blocks to define our\n",
    "# network. They also enable automatic-differentiation, which allows us to\n",
    "# define only the forward pass and let the libraries perform back-propagation\n",
    "# using automatic differentiation.\n",
    "#\n",
    "# In this question we will implement a multi-layer perceptron using the PyTorch\n",
    "# library.  Please complete the code for the MultiLayerPerceptron, training and\n",
    "# evaluating the model. Once you can train the two layer model, experiment with\n",
    "# adding more layers and report your observations\n",
    "#--------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZTcqWXuwqAje"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Fully connected neural network with one hidden layer\n",
    "#-------------------------------------------------\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        #################################################################################\n",
    "        # TODO: Initialize the modules required to implement the mlp with the layer     #\n",
    "        # configuration. input_size --> hidden_layers[0] --> hidden_layers[1] .... -->  #\n",
    "        # hidden_layers[-1] --> num_classes                                             #\n",
    "        # Make use of linear and relu layers from the torch.nn module                   #\n",
    "        #################################################################################\n",
    "        \n",
    "        layers = [] #Use the layers list to store a variable number of layers\n",
    "        \n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        layers.append(nn.Linear(input_size,hidden_layers[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        if len(hidden_layers)>1:\n",
    "          for i in range(len(hidden_layers)-1):\n",
    "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_layers[len(hidden_layers)-1],num_classes))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        # Enter the layers into nn.Sequential, so the model may \"see\" them\n",
    "        # Note the use of * in front of layers\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #################################################################################\n",
    "        # TODO: Implement the forward pass computations                                 #\n",
    "        # Note that you do not need to use the softmax operation at the end.            #\n",
    "        # Softmax is only required for the loss computation and the criterion used below#\n",
    "        # nn.CrossEntropyLoss() already integrates the softmax and the log loss together#\n",
    "        #################################################################################\n",
    "        \n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        out = self.layers(x)\n",
    "        \n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "E5IANG1sqApU"
   },
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron(input_size, hidden_size, num_classes).to(device)\n",
    "# Print model's state_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOjD7Db4qAvE",
    "outputId": "e7455545-6cc0-48f1-9e45-a38bb10a3d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layers.0.weight \t torch.Size([50, 3072])\n",
      "layers.0.bias \t torch.Size([50])\n",
      "layers.2.weight \t torch.Size([10, 50])\n",
      "layers.2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUFK6uDLqA6S",
    "outputId": "c046c904-5453-4fce-c513-f894c7bc8321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/245], Loss: 2.1102\n",
      "Epoch [1/10], Step [200/245], Loss: 2.1018\n",
      "Validataion accuracy is: 38.0 %\n",
      "Epoch [2/10], Step [100/245], Loss: 2.0656\n",
      "Epoch [2/10], Step [200/245], Loss: 2.0607\n",
      "Validataion accuracy is: 40.8 %\n",
      "Epoch [3/10], Step [100/245], Loss: 2.0553\n",
      "Epoch [3/10], Step [200/245], Loss: 2.0381\n",
      "Validataion accuracy is: 41.4 %\n",
      "Epoch [4/10], Step [100/245], Loss: 2.0232\n",
      "Epoch [4/10], Step [200/245], Loss: 2.0390\n",
      "Validataion accuracy is: 43.7 %\n",
      "Epoch [5/10], Step [100/245], Loss: 2.0482\n",
      "Epoch [5/10], Step [200/245], Loss: 2.0058\n",
      "Validataion accuracy is: 42.1 %\n",
      "Epoch [6/10], Step [100/245], Loss: 2.0266\n",
      "Epoch [6/10], Step [200/245], Loss: 2.0016\n",
      "Validataion accuracy is: 45.3 %\n",
      "Epoch [7/10], Step [100/245], Loss: 2.0101\n",
      "Epoch [7/10], Step [200/245], Loss: 1.9957\n",
      "Validataion accuracy is: 43.5 %\n",
      "Epoch [8/10], Step [100/245], Loss: 2.0030\n",
      "Epoch [8/10], Step [200/245], Loss: 2.0037\n",
      "Validataion accuracy is: 43.9 %\n",
      "Epoch [9/10], Step [100/245], Loss: 1.9660\n",
      "Epoch [9/10], Step [200/245], Loss: 1.9179\n",
      "Validataion accuracy is: 46.1 %\n",
      "Epoch [10/10], Step [100/245], Loss: 1.9530\n",
      "Epoch [10/10], Step [200/245], Loss: 2.0148\n",
      "Validataion accuracy is: 46.9 %\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    model.apply(weights_init)\n",
    "    model.train() #set dropout and batch normalization layers to training mode\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "    # Train the model\n",
    "    lr = learning_rate\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #################################################################################\n",
    "            # TODO: Implement the training code                                             #\n",
    "            # 1. Pass the images to the model                                               #\n",
    "            # 2. Compute the loss using the output and the labels.                          #\n",
    "            # 3. Compute gradients and update the model using the optimizer                 #\n",
    "            # Use examples in https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "            #################################################################################\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Code to update the lr\n",
    "        lr *= learning_rate_decay\n",
    "        update_lr(optimizer, lr)\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                ####################################################\n",
    "                # TODO: Implement the evaluation code              #\n",
    "                # 1. Pass the images to the model                  #\n",
    "                # 2. Get the most confident predicted class        #\n",
    "                ####################################################\n",
    "                # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                logits = model.forward(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "\n",
    "                # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
    "\n",
    "    ##################################################################################\n",
    "    # TODO: Now that you can train a simple two-layer MLP using above code, you can  #\n",
    "    # easily experiment with adding more layers and different layer configurations   #\n",
    "    # and let the pytorch library handle computing the gradients                     #\n",
    "    #                                                                                #\n",
    "    # Experiment with different number of layers (at least from 2 to 5 layers) and   #\n",
    "    # record the final validation accuracies Report your observations on how adding  #\n",
    "    # more layers to the MLP affects its behavior. Try to improve the model          #\n",
    "    # configuration using the validation performance as the guidance. You can        #\n",
    "    # experiment with different activation layers available in torch.nn, adding      #\n",
    "    # dropout layers, if you are interested. Use the best model on the validation    #\n",
    "    # set, to evaluate the performance on the test set once and report it            #\n",
    "    ##################################################################################\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "else:\n",
    "    # Run the test code once you have your by setting train flag to false\n",
    "    # and loading the best model\n",
    "\n",
    "    best_model = None\n",
    "    best_model = torch.load('model.ckpt')\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Test the model\n",
    "    model.eval() #set dropout and batch normalization layers to evaluation mode\n",
    "    \n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ####################################################\n",
    "            # TODO: Implement the evaluation code              #\n",
    "            # 1. Pass the images to the model                  #\n",
    "            # 2. Get the most confident predicted class        #\n",
    "            ####################################################\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if total == 1000:\n",
    "                break\n",
    "\n",
    "        print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ect7xtD5qA0l"
   },
   "outputs": [],
   "source": [
    "#Above is the one hidden layer fully connected neural network\n",
    "train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdgIoO6GqAun",
    "outputId": "1abbaeef-674b-4994-e396-38cc29770740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 44.7 %\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    model.apply(weights_init)\n",
    "    model.train() #set dropout and batch normalization layers to training mode\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "    # Train the model\n",
    "    lr = learning_rate\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #################################################################################\n",
    "            # TODO: Implement the training code                                             #\n",
    "            # 1. Pass the images to the model                                               #\n",
    "            # 2. Compute the loss using the output and the labels.                          #\n",
    "            # 3. Compute gradients and update the model using the optimizer                 #\n",
    "            # Use examples in https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "            #################################################################################\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Code to update the lr\n",
    "        lr *= learning_rate_decay\n",
    "        update_lr(optimizer, lr)\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                ####################################################\n",
    "                # TODO: Implement the evaluation code              #\n",
    "                # 1. Pass the images to the model                  #\n",
    "                # 2. Get the most confident predicted class        #\n",
    "                ####################################################\n",
    "                # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                logits = model.forward(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "\n",
    "                # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
    "\n",
    "    ##################################################################################\n",
    "    # TODO: Now that you can train a simple two-layer MLP using above code, you can  #\n",
    "    # easily experiment with adding more layers and different layer configurations   #\n",
    "    # and let the pytorch library handle computing the gradients                     #\n",
    "    #                                                                                #\n",
    "    # Experiment with different number of layers (at least from 2 to 5 layers) and   #\n",
    "    # record the final validation accuracies Report your observations on how adding  #\n",
    "    # more layers to the MLP affects its behavior. Try to improve the model          #\n",
    "    # configuration using the validation performance as the guidance. You can        #\n",
    "    # experiment with different activation layers available in torch.nn, adding      #\n",
    "    # dropout layers, if you are interested. Use the best model on the validation    #\n",
    "    # set, to evaluate the performance on the test set once and report it            #\n",
    "    ##################################################################################\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "else:\n",
    "    # Run the test code once you have your by setting train flag to false\n",
    "    # and loading the best model\n",
    "\n",
    "    best_model = None\n",
    "    best_model = torch.load('model.ckpt')\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Test the model\n",
    "    model.eval() #set dropout and batch normalization layers to evaluation mode\n",
    "    \n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ####################################################\n",
    "            # TODO: Implement the evaluation code              #\n",
    "            # 1. Pass the images to the model                  #\n",
    "            # 2. Get the most confident predicted class        #\n",
    "            ####################################################\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if total == 1000:\n",
    "                break\n",
    "\n",
    "        print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQL4GQv7qAdc",
    "outputId": "ac4992b2-3b31-4135-b724-dd5b847e1558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [1/10], Step [200/245], Loss: 2.3026\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [2/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [2/10], Step [200/245], Loss: 2.3025\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [3/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [3/10], Step [200/245], Loss: 2.3025\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [4/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [4/10], Step [200/245], Loss: 2.3026\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [5/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [5/10], Step [200/245], Loss: 2.3026\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [6/10], Step [100/245], Loss: 2.3025\n",
      "Epoch [6/10], Step [200/245], Loss: 2.3027\n",
      "Validataion accuracy is: 7.9 %\n",
      "Epoch [7/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [7/10], Step [200/245], Loss: 2.3026\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [8/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [8/10], Step [200/245], Loss: 2.3027\n",
      "Validataion accuracy is: 7.8 %\n",
      "Epoch [9/10], Step [100/245], Loss: 2.3026\n",
      "Epoch [9/10], Step [200/245], Loss: 2.3026\n",
      "Validataion accuracy is: 7.9 %\n",
      "Epoch [10/10], Step [100/245], Loss: 2.3025\n",
      "Epoch [10/10], Step [200/245], Loss: 2.3024\n",
      "Validataion accuracy is: 7.8 %\n",
      "Learning Rate: 0.001\n",
      "Hidden Size [2048, 1365, 910, 606, 404]\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "#--------------------------------\n",
    "# Hyper-parameters\n",
    "#--------------------------------\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [2048,1365,910,606,404]\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 200\n",
    "learning_rate = 1e-3  #2e-3,3e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg=0.001\n",
    "num_training= 49000\n",
    "num_validation =1000\n",
    "train = True\n",
    "        \n",
    "model = MultiLayerPerceptron(input_size, hidden_size, num_classes).to(device)    \n",
    "\n",
    "if train:\n",
    "    model.apply(weights_init)\n",
    "    model.train() #set dropout and batch normalization layers to training mode\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "    # Train the model\n",
    "    lr = learning_rate\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Code to update the lr\n",
    "        lr *= learning_rate_decay\n",
    "        update_lr(optimizer, lr)\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                logits = model.forward(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "\n",
    "                # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "    print(\"Learning Rate:\",learning_rate)\n",
    "    print(\"Hidden Size\", hidden_size)\n",
    "else:\n",
    "    # Run the test code once you have your by setting train flag to false\n",
    "    # and loading the best model\n",
    "\n",
    "    best_model = None\n",
    "    best_model = torch.load('model.ckpt')\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Test the model\n",
    "    model.eval() #set dropout and batch normalization layers to evaluation mode\n",
    "    \n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            logits = model.forward(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if total == 1000:\n",
    "                break\n",
    "\n",
    "        print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "        print(\"Learning Rate:\",learning_rate)\n",
    "        print(\"Hidden Size\", hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r16MaaURqAMQ"
   },
   "outputs": [],
   "source": [
    "#Learning Rate 1e-3\n",
    "'[50,50]Accuracy of the network on the 1000 test images: 44.1 %'\n",
    "'[600,600]Accuracy of the network on the 1000 test images: 45.9 %'\n",
    "'[100,100]Accuracy of the network on the 1000 test images: 46.4 %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyy0jnxRqAGs",
    "outputId": "34ed7f5d-8607-444a-d115-883cc358b90c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1536, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1536, out_features=768, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=768, out_features=384, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=384, out_features=192, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=192, out_features=10, bias=True)\n",
      "    (9): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMI0k9E4qABM",
    "outputId": "c8fd969b-3e5d-4237-a9ff-15310cadb0d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.0"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "606*2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So5oxUHXp_8G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Q4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
